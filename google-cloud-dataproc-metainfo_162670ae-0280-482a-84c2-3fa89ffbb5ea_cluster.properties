#Cluster properties
#Tue Nov 09 21:29:52 PST 2021
dataproc\:yarn.log-aggregation.enabled=true
dataproc\:dataproc.proxy.agent.endpoint=https\://us-west1.dataproc.cloud.google.com/
spark\:spark.yarn.am.memory=640m
distcp\:mapreduce.reduce.java.opts=-Xmx576m
yarn\:yarn.nodemanager.address=0.0.0.0\:8026
hdfs\:dfs.namenode.secondary.https-address=0.0.0.0\:9869
hdfs\:dfs.namenode.secondary.http-address=0.0.0.0\:9868
hdfs\:dfs.namenode.https-address=0.0.0.0\:9871
spark\:spark.sql.cbo.enabled=true
mapred\:mapreduce.map.cpu.vcores=1
yarn\:yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs=86400
mapred\:mapreduce.job.reduce.slowstart.completedmaps=0.95
spark\:spark.executor.memory=2688m
dataproc\:dataproc.scheduler.max-concurrent-jobs=5
mapred\:mapreduce.reduce.memory.mb=3072
dataproc\:dataproc.control.task.request.interval.millis=5000
hdfs\:dfs.datanode.https.address=0.0.0.0\:9865
hdfs\:dfs.namenode.servicerpc-address=cluster-desafio-dataproc-m\:8051
dataproc\:dataproc.proxy.agent.enablewebsockets=true
dataproc\:dataproc.monitoring.stackdriver.enable=false
dataproc\:dataproc.conscrypt.provider.enable=true
dataproc\:dataproc.cluster-ttl.report-yarn-activity=true
core\:fs.gs.block.size=134217728
spark\:spark.driver.maxResultSize=960m
mapred\:mapreduce.jobhistory.recovery.store.class=org.apache.hadoop.mapreduce.v2.hs.HistoryServerLeveldbStateStoreService
mapred\:mapreduce.map.java.opts=-Xmx2457m
mapred\:yarn.app.mapreduce.am.resource.cpu-vcores=1
dataproc\:dataproc.control.task.invalidation.interval.millis=5000
dataproc\:dataproc.worker.custom.init.actions.mode=RUN_BEFORE_SERVICES
spark\:spark.executor.cores=1
mapred\:yarn.app.mapreduce.am.command-opts=-Xmx2457m
spark\:spark.ui.port=0
distcp\:mapreduce.map.memory.mb=768
yarn-env\:YARN_TIMELINESERVER_HEAPSIZE=1920
dataproc\:agent.spark.driver.empty.jar=true
distcp\:mapreduce.map.java.opts=-Xmx576m
dataproc\:dataproc.control.task.stream.duration.sec=600
core\:hadoop.ssl.enabled.protocols=TLSv1,TLSv1.1,TLSv1.2
dataproc\:dataproc.proxy.backend.id=pyxmljlnarbcrftewdcepkl4lm
yarn\:yarn.scheduler.maximum-allocation-mb=6144
yarn-env\:YARN_RESOURCEMANAGER_HEAPSIZE=1920
dataproc\:am.primary_only=false
hdfs\:dfs.datanode.address=0.0.0.0\:9866
mapred\:mapreduce.task.io.sort.mb=256
dataproc\:dataproc.heartbeat.master.frequency.sec=30
dataproc\:job.history.to-gcs.enabled=true
mapred\:mapreduce.job.maps=15
hdfs\:dfs.namenode.service.handler.count=20
mapred\:mapreduce.job.reduces=5
hdfs\:dfs.datanode.http.address=0.0.0.0\:9864
dataproc\:simplified.scaling.enable=true
mapred\:mapreduce.map.memory.mb=3072
dataproc\:dataproc.components.activate=jupyter knox proxy-agent zeppelin zookeeper-server
dataproc\:dataproc.heartbeat.worker.frequency.sec=-1
hadoop-env\:HADOOP_DATANODE_OPTS=-Xmx512m
core\:fs.gs.metadata.cache.enable=false
hdfs\:dfs.datanode.ipc.address=0.0.0.0\:9867
yarn\:yarn.scheduler.minimum-allocation-mb=1
mapred\:yarn.app.mapreduce.am.resource.mb=3072
dataproc\:dataproc.proxy.agent.enablebanner=true
distcp\:mapreduce.reduce.memory.mb=768
hive\:hive.fetch.task.conversion=none
yarn\:yarn.nodemanager.resource.cpu-vcores=2
yarn\:yarn.nodemanager.resource.memory-mb=6144
dataproc\:dataproc.master.custom.init.actions.mode=RUN_BEFORE_SERVICES
hdfs\:dfs.namenode.lifeline.rpc-address=cluster-desafio-dataproc-m\:8050
yarn-env\:YARN_NODEMANAGER_HEAPSIZE=768
mapred-env\:HADOOP_JOB_HISTORYSERVER_HEAPSIZE=1920
mapred\:mapreduce.reduce.java.opts=-Xmx2457m
capacity-scheduler\:yarn.scheduler.capacity.root.default.ordering-policy=fair
dataproc\:dataproc.scheduler.max-memory-used=0.9
spark\:spark.scheduler.mode=FAIR
hdfs\:dfs.namenode.http-address=0.0.0.0\:9870
dataproc\:dataproc.proxy.public.hostname=https\://pyxmljlnarbcrftewdcepkl4lm-dot-us-west1.dataproc.googleusercontent.com
dataproc\:dataproc.job.metrics.monitor.interval.sec=60
spark\:spark.driver.memory=1920m
dataproc\:dataproc.proxy.agent.sessioncookie=_xsrf
spark\:spark.executorEnv.OPENBLAS_NUM_THREADS=1
spark\:spark.executor.instances=2
spark-env\:SPARK_DAEMON_MEMORY=1920m
mapred\:mapreduce.reduce.cpu.vcores=1
hdfs\:dfs.namenode.handler.count=40
